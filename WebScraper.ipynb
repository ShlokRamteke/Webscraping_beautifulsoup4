{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM230beUAUHOEAaOyEx8OEj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShlokRamteke/Webscraping_beautifulsoup4/blob/main/Copy_of_WebScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFUif60-8vX7"
      },
      "source": [
        "## Scraping Medium sites data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wypfcDr--2Mn"
      },
      "source": [
        "Installing and importing the required libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGBs-Lqa_He9"
      },
      "source": [
        "# Import the library\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUIWkR8wFe9b"
      },
      "source": [
        "A dictionary containg all the pulication links. To extracrt the data from these publication I have used \"/archive/year/month/day” in the publication url. This can help in scraping the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0aJ49mNMI5"
      },
      "source": [
        "urls = {\n",
        "    'Data Driven Investor': 'https://medium.com/datadriveninvestor/archive/{0}/{1:02d}/{2:02d}',\n",
        "    'Better Humans': 'https://medium.com/better-humans/archive/{0}/{1:02d}/{2:02d}',\n",
        "    'Better Marketing': 'https://medium.com/better-marketing/archive/{0}/{1:02d}/{2:02d}',\n",
        "    'UX Collective': 'https://uxdesign.cc/archive/{0}/{1:02d}/{2:02d}',\n",
        "    'The Startup': 'https://medium.com/swlh/archive/{0}/{1:02d}/{2:02d}',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY5TozXsc-YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0d8d5c-e36e-4807-b8b5-7c17d0f7b9f1"
      },
      "source": [
        "print(urls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Data Driven Investor': 'https://medium.com/datadriveninvestor/archive/{0}/{1:02d}/{2:02d}', 'Better Humans': 'https://medium.com/better-humans/archive/{0}/{1:02d}/{2:02d}', 'Better Marketing': 'https://medium.com/better-marketing/archive/{0}/{1:02d}/{2:02d}', 'UX Collective': 'https://uxdesign.cc/archive/{0}/{1:02d}/{2:02d}', 'The Startup': 'https://medium.com/swlh/archive/{0}/{1:02d}/{2:02d}'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t56IFeWdF06K"
      },
      "source": [
        "The bellow functions are used to convert the data taken from the webpage in useful format\\\n",
        "- The convert_day(day) function taskes the parameter a day of a year and return the tuple of form(month, day). This tells the month and day of that month in which it is located\n",
        "- is_leap(year) is used to know whether a given year is a leap year \n",
        "- get_claps(claps_str) function is used to convert a string from the webpage into an interger. This integer reperesents the number of claps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWfOOJ_fNRGf"
      },
      "source": [
        "\n",
        "\n",
        "def is_leap(year):\n",
        "    if year % 4 != 0:\n",
        "        return False\n",
        "    elif year % 100 != 0:\n",
        "        return True\n",
        "    elif year % 400 != 0:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "    \n",
        "def convert_day(day, year):\n",
        "    month_days = [31, 29 if is_leap(year) else 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
        "    m = 0\n",
        "    d = 0\n",
        "    while day > 0:\n",
        "        d = day\n",
        "        day -= month_days[m]\n",
        "        m += 1\n",
        "    return (m, d)\n",
        "\n",
        "def get_claps(claps_str):\n",
        "    if (claps_str is None) or (claps_str == '') or (claps_str.split is None):\n",
        "        return 0\n",
        "    split = claps_str.split('K')\n",
        "    claps = float(split[0])\n",
        "    claps = int(claps*1000) if len(split) == 2 else int(claps)\n",
        "    return claps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y37FTB0-HmdM"
      },
      "source": [
        "50 days are selected randomly from the the year 2020. This is shown in the bellow code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYdlIFUuOUC2"
      },
      "source": [
        "year = 2020\n",
        "selected_days = random.sample([i for i in range(1, 367 if is_leap(year) else 366)], 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpI0oq93H0jy"
      },
      "source": [
        "The bellow code all the data in puts in into a list called data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqJGcqiTRxDc"
      },
      "source": [
        "data = []\n",
        "article_id = 0\n",
        "i = 0\n",
        "n = len(selected_days)\n",
        "for d in selected_days:\n",
        "    i += 1\n",
        "    month, day = convert_day(d, year)\n",
        "    date = '{0}-{1:02d}-{2:02d}'.format(year, month, day)\n",
        "    print(f'{i} / {n} ; {date}')\n",
        "    for publication, url in urls.items():\n",
        "        \n",
        "        response = requests.get(url.format(year, month, day), allow_redirects=True)\n",
        "        print(url.format(year, month, day))\n",
        "        #if not response.url.startswith(url.format(year, month, day)):\n",
        "          #  continue\n",
        "        page = response.content\n",
        "        \n",
        "        soup = BeautifulSoup(page, 'html.parser')\n",
        "        articles = soup.find_all(\"div\", class_=\"postArticle postArticle--short js-postArticle js-trackPostPresentation js-trackPostScrolls\")\n",
        "        for article in articles:\n",
        "            title = article.find(\"h3\", class_=\"graf--title\")\n",
        "            if title is None:\n",
        "                continue\n",
        "            title = title.contents[0]\n",
        "            \n",
        "            article_id += 1\n",
        "            subtitle = article.find(\"h4\", class_=\"graf--subtitle\")\n",
        "            subtitle = subtitle.contents[0] if subtitle is not None else ''\n",
        "            article_url = article.find_all(\"a\")[3]['href'].split('?')[0]\n",
        "            claps = get_claps(article.find_all(\"button\")[1].contents[0])\n",
        "            reading_time = article.find(\"span\", class_=\"readingTime\")\n",
        "            reading_time = 0 if reading_time is None else int(reading_time['title'].split(' ')[0])\n",
        "            responses = article.find_all(\"a\")\n",
        "            if len(responses) == 7:\n",
        "                responses = responses[6].contents[0].split(' ')\n",
        "                if len(responses) == 0:\n",
        "                    responses = 0\n",
        "                else:\n",
        "                    responses = responses[0]\n",
        "            else:\n",
        "                responses = 0\n",
        "\n",
        "            data.append([article_id, article_url, title, subtitle, claps, responses, reading_time, publication, date])\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEwtNeyUH8vo"
      },
      "source": [
        "The list is then converted into a dataframe medium_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt54b8OXSRYk"
      },
      "source": [
        "medium_df = pd.DataFrame(data, columns=['id', 'url', 'title', 'subtitle', 'claps', 'responses', 'reading_time', 'publication', 'date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9UEvpFtT9fI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68347a6c-bd42-4ba4-9da1-7d27857181fc"
      },
      "source": [
        "medium_df['publication'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Data Driven Investor', 'Better Humans', 'Better Marketing',\n",
              "       'UX Collective', 'The Startup'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQEVtBW8IMgb"
      },
      "source": [
        "The dataframe is then exported to a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7aBCITJXSn_"
      },
      "source": [
        "medium_df.to_csv('medium_data.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V07rZCs9XiDn"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
